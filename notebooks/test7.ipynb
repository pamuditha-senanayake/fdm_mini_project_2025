{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-03T01:36:13.778468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load and clean data\n",
    "df = pd.read_csv(\"../data/raw/data.csv\")\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna(subset=[\"Customer_ID\", \"Amount\", \"Product_Category\"])\n",
    "df = df.fillna({\"Income\": \"Unknown\", \"Feedback\": \"No Feedback\"})\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Outlier handling for numerical columns\n",
    "num_cols = [\"Age\", \"Amount\", \"Total_Purchases\"]\n",
    "for col in num_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "# Feature engineering\n",
    "df['Avg_Amount'] = df['Amount'] / df['Total_Purchases'].replace(0, 1)  # Avoid division by zero\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day_of_Week'] = df['Date'].dt.dayofweek\n",
    "\n",
    "# Encode categorical variables\n",
    "ordinal_cols = [\"Income\"]  # Assuming Income is ordinal (e.g., Low, Medium, High)\n",
    "nominal_cols = [\"Gender\", \"Product_Category\"]  # Customer_Segment is target, not feature\n",
    "\n",
    "# Label encoding for ordinal variables\n",
    "for col in ordinal_cols:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n",
    "\n",
    "# One-hot encoding for nominal variables\n",
    "ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "ohe_data = pd.DataFrame(ohe.fit_transform(df[nominal_cols]),\n",
    "                        columns=ohe.get_feature_names_out(nominal_cols),\n",
    "                        index=df.index)\n",
    "df = pd.concat([df.drop(nominal_cols, axis=1), ohe_data], axis=1)\n",
    "\n",
    "# Prepare features and target\n",
    "X = df[[\"Age\", \"Income\", \"Amount\", \"Total_Purchases\", \"Avg_Amount\", \"Month\", \"Day_of_Week\"] +\n",
    "       list(ohe.get_feature_names_out(nominal_cols))]\n",
    "y = LabelEncoder().fit_transform(df[\"Customer_Segment\"])  # Encode target\n",
    "\n",
    "# Impute missing values and scale numerical features\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "scaler = StandardScaler()\n",
    "X[num_cols + [\"Avg_Amount\", \"Month\", \"Day_of_Week\"]] = imputer.fit_transform(X[num_cols + [\"Avg_Amount\", \"Month\", \"Day_of_Week\"]])\n",
    "X[num_cols + [\"Avg_Amount\", \"Month\", \"Day_of_Week\"]] = scaler.fit_transform(X[num_cols + [\"Avg_Amount\", \"Month\", \"Day_of_Week\"]])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Hyperparameter tuning for RandomForest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Cross-validation score\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=5, scoring='f1_weighted')\n",
    "print(\"\\nCross-Validation F1 Scores:\", cv_scores)\n",
    "print(\"Mean CV F1 Score:\", cv_scores.mean())\n",
    "\n",
    "# Feature importance\n",
    "importances = best_model.feature_importances_\n",
    "feature_imp = pd.DataFrame({'Feature': X.columns, 'Importance': importances}).sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nFeature Importance:\\n\", feature_imp)"
   ],
   "id": "7e2d5db21571806a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

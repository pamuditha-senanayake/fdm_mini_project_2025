{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-04T00:49:31.178022Z",
     "start_time": "2025-10-04T00:49:27.326138Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Sales Prediction & Customer Insights Application\n",
    "A complete ML application for sales analysis, customer segmentation, and insights generation.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import gradio as gr\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_absolute_error\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "from pathlib import Path\n",
    "import io\n",
    "from base64 import b64encode\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "class Config:\n",
    "    \"\"\"Configuration class for the application.\"\"\"\n",
    "    DATA_PATH: str = \"../data.csv\"\n",
    "    TEST_SIZE: float = 0.2\n",
    "    RANDOM_STATE: int = 42\n",
    "    MODEL_PATH: str = \"predictive_model.joblib\"\n",
    "    CLUSTER_MODEL_PATH: str = \"clustering_model.joblib\"\n",
    "    PREPROCESSOR_PATH: str = \"preprocessor.joblib\"\n",
    "    MODEL_PARAMS: dict = {\n",
    "        'n_estimators': [500, 1000],\n",
    "        'learning_rate': [0.01, 0.05],\n",
    "        'max_depth': [5, 10],\n",
    "        'num_leaves': [31, 64]\n",
    "    }\n",
    "    CATEGORICAL_COLUMNS: List[str] = [\n",
    "        'Gender', 'Income', 'Customer_Segment',\n",
    "        'Product_Category', 'Shipping_Method', 'Payment_Method'\n",
    "    ]\n",
    "    FEATURE_COLUMNS: List[str] = [\n",
    "        'Year', 'Month', 'Day', 'Weekday', 'Hour', 'Product_Category',\n",
    "        'Customer_Segment', 'Shipping_Method', 'Payment_Method', 'Amount',\n",
    "        'Total_Amount', 'Ratings', 'Age', 'Rolling_7d', 'Rolling_14d', 'Segment_Product'\n",
    "    ]\n",
    "    CLUSTER_FEATURES: List[str] = ['Age', 'Income', 'Total_Purchases', 'Ratings', 'Amount', 'Total_Amount']\n",
    "    N_CLUSTERS: int = 4\n",
    "    PURCHASE_THRESHOLD: float = None\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Data Preprocessor\n",
    "# -----------------------------\n",
    "class DataPreprocessor:\n",
    "    \"\"\"Handles data loading, preprocessing, and feature engineering.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.category_mappings: Dict[str, Dict] = {}\n",
    "        self.config = Config()\n",
    "        self.data_path = self._resolve_data_path()\n",
    "        self.scaler = StandardScaler()\n",
    "        self._preprocessed_data: pd.DataFrame = None\n",
    "        self._X: pd.DataFrame = None\n",
    "        self._y: pd.Series = None\n",
    "\n",
    "    def _resolve_data_path(self) -> Path:\n",
    "        \"\"\"Resolve the path to data.csv robustly regardless of CWD.\n",
    "\n",
    "        Search order:\n",
    "        1) DATA_CSV environment variable (absolute or relative to this file)\n",
    "        2) Config.DATA_PATH relative to this file\n",
    "        3) ./data.csv next to this file\n",
    "        4) ../data.csv (one directory up)\n",
    "        5) ../../data.csv (two directories up)\n",
    "        \"\"\"\n",
    "        # If env var is set, prefer it\n",
    "        env_path = os.getenv(\"DATA_CSV\")\n",
    "        base_dir = Path(__file__).resolve().parent\n",
    "\n",
    "        candidate_paths = []\n",
    "\n",
    "        if env_path:\n",
    "            env_p = Path(env_path)\n",
    "            if not env_p.is_absolute():\n",
    "                env_p = base_dir / env_p\n",
    "            candidate_paths.append(env_p)\n",
    "\n",
    "        # Config path relative to this file\n",
    "        cfg_path = Path(self.config.DATA_PATH)\n",
    "        if not cfg_path.is_absolute():\n",
    "            cfg_path = base_dir / cfg_path\n",
    "        candidate_paths.append(cfg_path)\n",
    "\n",
    "        # Common fallbacks\n",
    "        candidate_paths.extend([\n",
    "            base_dir / \"data.csv\",\n",
    "            base_dir.parent / \"data.csv\",\n",
    "            base_dir.parent.parent / \"data.csv\",\n",
    "        ])\n",
    "\n",
    "        for p in candidate_paths:\n",
    "            if p.exists():\n",
    "                return p\n",
    "\n",
    "        # If nothing found, fall back to original config path (even if missing) for clearer error\n",
    "        return candidate_paths[0]\n",
    "\n",
    "    def load_and_preprocess(self) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        \"\"\"Load and preprocess the dataset with NaN handling.\"\"\"\n",
    "        if self._preprocessed_data is not None:\n",
    "            return self._X, self._y\n",
    "\n",
    "        print(\"Loading data...\")\n",
    "        # Resolve again in case env or files changed between runs\n",
    "        self.data_path = self._resolve_data_path()\n",
    "        if not self.data_path.exists():\n",
    "            raise FileNotFoundError(f\"Could not locate data.csv. Tried: {self.data_path}\")\n",
    "        print(f\"Reading CSV from: {self.data_path}\")\n",
    "        df = pd.read_csv(self.data_path)\n",
    "\n",
    "        # Handle missing values\n",
    "        print(\"Handling missing values...\")\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype in ['int64', 'float64']:\n",
    "                df[col] = df[col].fillna(df[col].mean())\n",
    "            elif col in self.config.CATEGORICAL_COLUMNS:\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "        # Replace invalid time values\n",
    "        df['Time'] = df['Time'].replace('######', np.nan)\n",
    "        df['Hour'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce').dt.hour\n",
    "        df['Hour'] = df['Hour'].fillna(df['Hour'].mean())\n",
    "\n",
    "        # Process categorical variables\n",
    "        print(\"Encoding categorical variables...\")\n",
    "        for col in self.config.CATEGORICAL_COLUMNS:\n",
    "            df[col] = df[col].astype('category')\n",
    "            self.category_mappings[col] = dict(enumerate(df[col].cat.categories))\n",
    "            self.category_mappings[f\"{col}_inv\"] = {v: k for k, v in self.category_mappings[col].items()}\n",
    "            df[col] = df[col].cat.codes\n",
    "\n",
    "        # Process datetime features\n",
    "        print(\"Extracting datetime features...\")\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "        df = df.dropna(subset=['Date'])\n",
    "        df['Day'] = df['Date'].dt.day\n",
    "        df['Weekday'] = df['Date'].dt.weekday\n",
    "        df['Year'] = df['Date'].dt.year\n",
    "        df['Month'] = df['Date'].dt.month\n",
    "\n",
    "        # Sort and compute rolling averages\n",
    "        print(\"Computing rolling features...\")\n",
    "        df = df.sort_values('Date')\n",
    "        df['Rolling_7d'] = df.groupby('Product_Category')['Total_Purchases'].transform(\n",
    "            lambda x: x.rolling(7, min_periods=1).mean().fillna(method='ffill')\n",
    "        )\n",
    "        df['Rolling_14d'] = df.groupby('Product_Category')['Total_Purchases'].transform(\n",
    "            lambda x: x.rolling(14, min_periods=1).mean().fillna(method='ffill')\n",
    "        )\n",
    "        df['Segment_Product'] = df['Customer_Segment'] * df['Product_Category']\n",
    "\n",
    "        # Set purchase threshold as median\n",
    "        self.config.PURCHASE_THRESHOLD = df['Total_Purchases'].median()\n",
    "        print(f\"Purchase threshold set to: {self.config.PURCHASE_THRESHOLD}\")\n",
    "\n",
    "        self._preprocessed_data = df\n",
    "        self._X = df[self.config.FEATURE_COLUMNS]\n",
    "        self._y = (df['Total_Purchases'] > self.config.PURCHASE_THRESHOLD).astype(int)\n",
    "\n",
    "        print(f\"Preprocessing complete. Dataset shape: {df.shape}\")\n",
    "        return self._X, self._y\n",
    "\n",
    "    def get_cluster_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Prepare data for clustering with NaN handling.\"\"\"\n",
    "        df = self._preprocessed_data.copy()\n",
    "        cluster_df = df[self.config.CLUSTER_FEATURES]\n",
    "        cluster_df['Income'] = cluster_df['Income'].astype('category').cat.codes\n",
    "        numerical_cols = cluster_df.select_dtypes(include=['float', 'int']).columns\n",
    "        cluster_df[numerical_cols] = self.scaler.fit_transform(cluster_df[numerical_cols].fillna(0))\n",
    "        return cluster_df\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Model Trainer\n",
    "# -----------------------------\n",
    "class ModelTrainer:\n",
    "    \"\"\"Handles model training for both prediction and clustering.\"\"\"\n",
    "\n",
    "    def __init__(self, preprocessor: DataPreprocessor):\n",
    "        self.preprocessor = preprocessor\n",
    "        self.model = None\n",
    "        self.metrics = {}\n",
    "        self.cluster_model = None\n",
    "        self.cluster_labels = None\n",
    "\n",
    "    def train_predictive_model(self) -> None:\n",
    "        \"\"\"Train the classification model with hyperparameter tuning.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Training Predictive Model...\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        X, y = self.preprocessor.load_and_preprocess()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=Config().TEST_SIZE, random_state=Config().RANDOM_STATE\n",
    "        )\n",
    "\n",
    "        print(f\"Training set size: {len(X_train)}\")\n",
    "        print(f\"Test set size: {len(X_test)}\")\n",
    "\n",
    "        base_model = lgb.LGBMClassifier(random_state=Config().RANDOM_STATE)\n",
    "        grid_search = GridSearchCV(\n",
    "            base_model, Config().MODEL_PARAMS, cv=5, scoring='accuracy', n_jobs=-1, verbose=1\n",
    "        )\n",
    "\n",
    "        print(\"\\nPerforming grid search...\")\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        self.model = grid_search.best_estimator_\n",
    "\n",
    "        print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        self.metrics['accuracy'] = accuracy_score(y_test, y_pred)\n",
    "        self.metrics['r2'] = r2_score(y_test, y_pred)\n",
    "        self.metrics['mae'] = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        print(f\"\\nModel Performance:\")\n",
    "        print(f\"  Accuracy: {self.metrics['accuracy']:.4f}\")\n",
    "        print(f\"  RÂ²: {self.metrics['r2']:.4f}\")\n",
    "        print(f\"  MAE: {self.metrics['mae']:.4f}\")\n",
    "\n",
    "        # Save the trained predictive model\n",
    "        joblib.dump(self.model, Config().MODEL_PATH)\n",
    "        print(f\"\\nâœ“ Model saved to '{Config().MODEL_PATH}'\")\n",
    "\n",
    "    def train_clustering_model(self) -> None:\n",
    "        \"\"\"Train K-Means clustering for customer segmentation.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Training Clustering Model...\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        cluster_data = self.preprocessor.get_cluster_data()\n",
    "        print(f\"Clustering {len(cluster_data)} customers into {Config().N_CLUSTERS} segments...\")\n",
    "\n",
    "        self.cluster_model = KMeans(n_clusters=Config().N_CLUSTERS, random_state=Config().RANDOM_STATE)\n",
    "        self.cluster_labels = self.cluster_model.fit_predict(cluster_data)\n",
    "\n",
    "        # Save the trained clustering model\n",
    "        joblib.dump(self.cluster_model, Config().CLUSTER_MODEL_PATH)\n",
    "        print(f\"âœ“ Clustering model saved to '{Config().CLUSTER_MODEL_PATH}'\")\n",
    "\n",
    "    def save_preprocessor(self) -> None:\n",
    "        \"\"\"Save the preprocessor for later use.\"\"\"\n",
    "        joblib.dump(self.preprocessor, Config().PREPROCESSOR_PATH)\n",
    "        print(f\"âœ“ Preprocessor saved to '{Config().PREPROCESSOR_PATH}'\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Insights Generator\n",
    "# -----------------------------\n",
    "class InsightsGenerator:\n",
    "    \"\"\"Generates insights and visualizations from the data.\"\"\"\n",
    "\n",
    "    def __init__(self, preprocessor: DataPreprocessor, trainer: ModelTrainer):\n",
    "        self.preprocessor = preprocessor\n",
    "        self.trainer = trainer\n",
    "\n",
    "    def generate_descriptive_insights(self) -> str:\n",
    "        \"\"\"Generate descriptive statistics and insights.\"\"\"\n",
    "        df = self.preprocessor._preprocessed_data\n",
    "        insights = []\n",
    "\n",
    "        insights.append(\"### Demographic Insights\")\n",
    "        insights.append(f\"- Average Age: {df['Age'].mean():.2f}\")\n",
    "        insights.append(f\"- Gender Distribution: {df['Gender'].value_counts(normalize=True).to_dict()}\")\n",
    "        insights.append(f\"- Income Levels: {df['Income'].value_counts(normalize=True).to_dict()}\")\n",
    "\n",
    "        insights.append(\"\\n### Purchase Behavior\")\n",
    "        insights.append(f\"- Average Total Purchases: {df['Total_Purchases'].mean():.2f}\")\n",
    "        insights.append(f\"- Average Amount: {df['Amount'].mean():.2f}\")\n",
    "        insights.append(f\"- Top Product Categories: {df['Product_Category'].value_counts().head(3).to_dict()}\")\n",
    "\n",
    "        insights.append(\"\\n### Temporal Patterns\")\n",
    "        insights.append(f\"- Peak Hour: {df['Hour'].mode()[0]}\")\n",
    "        insights.append(f\"- Peak Month: {df['Month'].mode()[0]}\")\n",
    "\n",
    "        return \"\\n\".join(insights)\n",
    "\n",
    "    def generate_segmentation_insights(self) -> str:\n",
    "        \"\"\"Generate insights from clustering.\"\"\"\n",
    "        if self.trainer.cluster_labels is None:\n",
    "            return \"Clustering not performed yet.\"\n",
    "\n",
    "        df = self.preprocessor._preprocessed_data.copy()\n",
    "        df['Cluster'] = self.trainer.cluster_labels\n",
    "        insights = []\n",
    "\n",
    "        insights.append(\"### Customer Segments\")\n",
    "        for cluster in range(Config().N_CLUSTERS):\n",
    "            cluster_df = df[df['Cluster'] == cluster]\n",
    "            insights.append(f\"\\n#### Segment {cluster + 1} ({len(cluster_df)} customers)\")\n",
    "            insights.append(f\"- Avg Age: {cluster_df['Age'].mean():.2f}\")\n",
    "            insights.append(f\"- Avg Purchases: {cluster_df['Total_Purchases'].mean():.2f}\")\n",
    "            insights.append(f\"- Avg Ratings: {cluster_df['Ratings'].mean():.2f}\")\n",
    "            insights.append(f\"- Common Income: {cluster_df['Income'].mode()[0]}\")\n",
    "\n",
    "        return \"\\n\".join(insights)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Predictor\n",
    "# -----------------------------\n",
    "class Predictor:\n",
    "    \"\"\"Handles predictions for new data.\"\"\"\n",
    "\n",
    "    def __init__(self, trainer: ModelTrainer):\n",
    "        self.trainer = trainer\n",
    "        self.preprocessor = trainer.preprocessor\n",
    "        self.config = Config()\n",
    "        self._cached_means = None\n",
    "\n",
    "    def _get_cached_means(self) -> Dict[str, float]:\n",
    "        \"\"\"Cache mean values for performance.\"\"\"\n",
    "        if self._cached_means is None:\n",
    "            X, _ = self.preprocessor.load_and_preprocess()\n",
    "            self._cached_means = {\n",
    "                'Total_Amount': X['Total_Amount'].mean(),\n",
    "                'Rolling_7d': X['Rolling_7d'].mean(),\n",
    "                'Rolling_14d': X['Rolling_14d'].mean()\n",
    "            }\n",
    "        return self._cached_means\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Model Loader\n",
    "# -----------------------------\n",
    "def load_models():\n",
    "    \"\"\"Load saved models and preprocessor.\"\"\"\n",
    "    if not os.path.exists(Config().MODEL_PATH):\n",
    "        raise FileNotFoundError(f\"Model file not found: {Config().MODEL_PATH}\")\n",
    "    if not os.path.exists(Config().CLUSTER_MODEL_PATH):\n",
    "        raise FileNotFoundError(f\"Clustering model file not found: {Config().CLUSTER_MODEL_PATH}\")\n",
    "    if not os.path.exists(Config().PREPROCESSOR_PATH):\n",
    "        raise FileNotFoundError(f\"Preprocessor file not found: {Config().PREPROCESSOR_PATH}\")\n",
    "\n",
    "    print(\"\\nLoading saved models...\")\n",
    "    preprocessor = joblib.load(Config().PREPROCESSOR_PATH)\n",
    "    model = joblib.load(Config().MODEL_PATH)\n",
    "    cluster_model = joblib.load(Config().CLUSTER_MODEL_PATH)\n",
    "\n",
    "    print(\"âœ“ Models loaded successfully!\")\n",
    "\n",
    "    return preprocessor, model, cluster_model\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Gradio UI\n",
    "# -----------------------------\n",
    "def create_ui() -> gr.Blocks:\n",
    "    \"\"\"Create Gradio interface with Get Insights button.\"\"\"\n",
    "\n",
    "    def get_insights():\n",
    "        \"\"\"Generate and return insights when button is clicked.\"\"\"\n",
    "        try:\n",
    "            # Load models\n",
    "            preprocessor, model, cluster_model = load_models()\n",
    "\n",
    "            # Create trainer object with loaded models\n",
    "            trainer = ModelTrainer(preprocessor)\n",
    "            trainer.model = model\n",
    "            trainer.cluster_model = cluster_model\n",
    "\n",
    "            # Load preprocessed data and cluster labels\n",
    "            X, y = preprocessor.load_and_preprocess()\n",
    "            cluster_data = preprocessor.get_cluster_data()\n",
    "            trainer.cluster_labels = cluster_model.predict(cluster_data)\n",
    "\n",
    "            # Calculate metrics\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=Config().TEST_SIZE, random_state=Config().RANDOM_STATE\n",
    "            )\n",
    "            y_pred = model.predict(X_test)\n",
    "            trainer.metrics = {\n",
    "                'accuracy': accuracy_score(y_test, y_pred),\n",
    "                'r2': r2_score(y_test, y_pred),\n",
    "                'mae': mean_absolute_error(y_test, y_pred)\n",
    "            }\n",
    "\n",
    "            # Generate insights\n",
    "            insights_gen = InsightsGenerator(preprocessor, trainer)\n",
    "\n",
    "            metrics_text = (f\"**Model Performance:** \"\n",
    "                          f\"Accuracy = {round(trainer.metrics['accuracy'] * 100, 2)}%, \"\n",
    "                          f\"RÂ² = {round(trainer.metrics['r2'], 3)}, \"\n",
    "                          f\"MAE = {round(trainer.metrics['mae'], 3)}\")\n",
    "\n",
    "            desc_insights = insights_gen.generate_descriptive_insights()\n",
    "            seg_insights = insights_gen.generate_segmentation_insights()\n",
    "\n",
    "            return metrics_text, desc_insights, seg_insights\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            error_msg = f\"âŒ Error: {str(e)}\\n\\nPlease train the models first by running the training script.\"\n",
    "            return error_msg, \"\", \"\"\n",
    "        except Exception as e:\n",
    "            error_msg = f\"âŒ Error generating insights: {str(e)}\"\n",
    "            return error_msg, \"\", \"\"\n",
    "\n",
    "    with gr.Blocks(title=\"Sales Insights App\") as demo:\n",
    "        gr.Markdown(\"## ðŸ›’ Sales Prediction & Customer Insights App\")\n",
    "\n",
    "        with gr.Row():\n",
    "            get_insights_btn = gr.Button(\"ðŸ” Get Insights\", variant=\"primary\", size=\"lg\")\n",
    "\n",
    "        metrics_output = gr.Markdown(\"\")\n",
    "        desc_insights_output = gr.Markdown(\"\")\n",
    "        seg_insights_output = gr.Markdown(\"\")\n",
    "\n",
    "        get_insights_btn.click(\n",
    "            fn=get_insights,\n",
    "            outputs=[metrics_output, desc_insights_output, seg_insights_output]\n",
    "        )\n",
    "\n",
    "    return demo\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main Execution\n",
    "# -----------------------------\n",
    "def train_models():\n",
    "    \"\"\"Train and save all models.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"SALES PREDICTION & CUSTOMER INSIGHTS APP\")\n",
    "    print(\"TRAINING MODE\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "    # Initialize components\n",
    "    preprocessor = DataPreprocessor()\n",
    "    trainer = ModelTrainer(preprocessor)\n",
    "\n",
    "    # Train models\n",
    "    trainer.train_predictive_model()\n",
    "    trainer.train_clustering_model()\n",
    "\n",
    "    # Save preprocessor\n",
    "    trainer.save_preprocessor()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"âœ“ All models trained and saved successfully!\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "def launch_app():\n",
    "    \"\"\"Launch the Gradio interface.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Launching Gradio Interface...\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "    demo = create_ui()\n",
    "    demo.launch()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # First, train the models\n",
    "    train_models()\n",
    "\n",
    "    # Then launch the app\n",
    "    launch_app()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "SALES PREDICTION & CUSTOMER INSIGHTS APP\n",
      "TRAINING MODE\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 469\u001B[39m\n\u001B[32m    464\u001B[39m     demo.launch()\n\u001B[32m    467\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m\"\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    468\u001B[39m     \u001B[38;5;66;03m# First, train the models\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m469\u001B[39m     \u001B[43mtrain_models\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    471\u001B[39m     \u001B[38;5;66;03m# Then launch the app\u001B[39;00m\n\u001B[32m    472\u001B[39m     launch_app()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 442\u001B[39m, in \u001B[36mtrain_models\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    439\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m=\u001B[39m\u001B[33m\"\u001B[39m*\u001B[32m50\u001B[39m + \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    441\u001B[39m \u001B[38;5;66;03m# Initialize components\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m442\u001B[39m preprocessor = \u001B[43mDataPreprocessor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    443\u001B[39m trainer = ModelTrainer(preprocessor)\n\u001B[32m    445\u001B[39m \u001B[38;5;66;03m# Train models\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 65\u001B[39m, in \u001B[36mDataPreprocessor.__init__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     63\u001B[39m \u001B[38;5;28mself\u001B[39m.category_mappings: Dict[\u001B[38;5;28mstr\u001B[39m, Dict] = {}\n\u001B[32m     64\u001B[39m \u001B[38;5;28mself\u001B[39m.config = Config()\n\u001B[32m---> \u001B[39m\u001B[32m65\u001B[39m \u001B[38;5;28mself\u001B[39m.data_path = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_resolve_data_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     66\u001B[39m \u001B[38;5;28mself\u001B[39m.scaler = StandardScaler()\n\u001B[32m     67\u001B[39m \u001B[38;5;28mself\u001B[39m._preprocessed_data: pd.DataFrame = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 83\u001B[39m, in \u001B[36mDataPreprocessor._resolve_data_path\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     81\u001B[39m \u001B[38;5;66;03m# If env var is set, prefer it\u001B[39;00m\n\u001B[32m     82\u001B[39m env_path = os.getenv(\u001B[33m\"\u001B[39m\u001B[33mDATA_CSV\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m83\u001B[39m base_dir = Path(\u001B[34;43m__file__\u001B[39;49m).resolve().parent\n\u001B[32m     85\u001B[39m candidate_paths = []\n\u001B[32m     87\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m env_path:\n",
      "\u001B[31mNameError\u001B[39m: name '__file__' is not defined"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
